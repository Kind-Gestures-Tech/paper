\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{natbib}
\usepackage{hyperref}

\begin{document}

\title{Exploring Generative Pre-trained Transformers within Deep Learning Architectures }
\author{Saransh Sharma}
\date{}

\maketitle

Generative Pre-trained Transformers (GPTs) represent a sophisticated category within the broader domain of deep learning models in artificial intelligence. Deep learning, a subset of machine learning, involves the use of algorithms that infer patterns and make decisions based on extensive datasets \citep{lecun2015deep}. These models operate by adjusting a function based on input data, a process reminiscent of the learning mechanisms observed in biological neural networks, although the analogy is not direct or comprehensive \citep{schmidhuber2015deep}.

Deep learning architectures, particularly those like GPTs, are structured in a hierarchical manner, where each layer or node within the model can be seen as engaging in a form of 'learning' from the data it processes. These nodes are interconnected, allowing for the exchange and modification of information as it propagates through the network. This layered approach enables the handling of complex, non-linear relationships in data, a capability facilitated by the use of activation functions that introduce non-linearity into the learning process \citep{goodfellow2016deep}.

One of the pivotal mechanisms in deep learning is backpropagation, which is employed to refine the model's parameters through a process analogous to error correction, tracing the output back to the input to adjust the weights of connections for improved accuracy in future predictions \citep{rumelhart1986learning}.

It is crucial to acknowledge the intensive computational resources required by such models, which necessitates significant processing power to perform the iterative optimizations essential for achieving generalized and robust predictive capabilities \citep{strubell2019energy}.

In summary, while GPTs and other deep learning models draw some inspiration from biological neural networks, it is imperative to recognize the distinctions and the complexity inherent in these artificial systems. Their ability to process and learn from vast datasets through intricate networks of interconnected nodes marks a significant advancement in the field of artificial intelligence, albeit with ongoing debates regarding their full scope of applicability and analogy to human cognitive processes.

\section{Distinctive Features of GPT Models}

A pivotal development that distinguishes Generative Pre-trained Transformers (GPTs) from other deep learning models is articulated in the seminal work by \citet{vaswani2017attention}, titled "Attention is All You Need". This paper introduced a novel architecture that eschews traditional sequence-based processing in favor of a mechanism known as self-attention. Unlike earlier models that processed input data sequentially, the self-attention mechanism in GPT models evaluates the input by computing a weighted sum of all input elements, assessing the relevance of each word in the context of the entire sequence. This is further augmented by positional encoding, ensuring that the model retains an understanding of the sequence order, a crucial aspect for comprehending the meaning embedded in the sequence.

The architecture of GPT models incorporates multiple transformer blocks, each employing self-attention mechanisms. This design enables the model to capture the multifaceted nature of the input data, facilitating the learning of complex data representations. Consequently, GPT models excel in predicting subsequent sequences of input, leveraging their extensive training on large corpora of text to generate contextually relevant and coherent outputs.

\subsection{Implications of Self-Attention in GPT}

The adoption of self-attention mechanisms within GPT models heralds a significant shift in how machines process and interpret language. By evaluating the entire input sequence simultaneously, GPT models can discern nuanced patterns and relationships within the data, transcending the limitations of sequential analysis. This capability underpins the models' proficiency in a wide array of natural language processing tasks, from language translation to content generation, showcasing their versatility and the depth of understanding they can achieve.

\section{Parrot Repeating: The Limitations of GPTs in Context Awareness}

Generative Pre-trained Transformers (GPTs), synonymous with Large Language Models (LLMs), have been critiqued for their propensity to generate outputs that may lack genuine understanding or context, akin to a parrot's repetition. This analogy finds a parallel in the Chinese proverb suggesting that if monkeys were given typewriters, they would eventually produce Shakespeare's worksâ€”a concept explored by Richard Dawkins in his calculations regarding probability and randomness \citep{dawkins_monkeys}.

While GPTs demonstrate remarkable proficiency in discerning patterns within language, their ability to grasp the underlying context or intent remains a significant challenge. This limitation is evident in numerous instances where GPTs and other LLMs yield interpretations and outputs that can be misleading or inaccurately aligned with the intended meaning. A phenomenon commonly referred to as "hallucination" within this context, where GPTs generate arbitrary outputs under the guise of producing syntactically correct sentences, underscores the issue of accuracy versus plausibility in language generation \citep{gpt_hallucination}.

Furthermore, the challenge of context awareness in GPTs is compounded by limitations in memory retention. Despite attempts to augment GPTs with external memory mechanisms, the architecture inherently struggles to accommodate a vast number of tokens simultaneously. The capacity to process and retain information, dictated by the model's token limit, influences the attention mechanism's ability to generate relevant outputs. However, the integration of long-term memory retention into the current models of GPTs remains an unresolved issue, leading to observable shortcomings in their performance across various applications \citep{gpt_memory_limitations}.

\subsection{Technical Challenges in Overcoming Parrot-Like Repetitions}

Addressing the parrot-like repetitions and enhancing the context-aware capabilities of GPTs involve navigating several technical challenges. These include the development of more sophisticated attention mechanisms, the incorporation of external memory modules capable of supporting a broader context, and the implementation of algorithms designed to discern intent more accurately. The journey towards more contextually aware and less parrot-like GPTs necessitates ongoing research and innovation within the field of artificial intelligence and natural language processing \citep{ai_innovation_challenges}.



\section{Background}

The current Healthcare data model is known as EHR that stands for Electronic Health Records, however data fragmentaion across different streams is challneging in the industry. How ever there are no large language in the medical industry due to strict regulation such as HIPAA protects the patients data and medical language is full of specifitiy , full of technical terms and nuances that may not apt for LLM to full grasp and reason with. However there are some models out there such as John Snow Labs BioGPT speciflcay designed for medical domain and Mis


\bibliographystyle{plainnat}
\bibliography{references}

\end{document}
